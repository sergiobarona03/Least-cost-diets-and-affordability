---
title: "**Transmisión de precios y ajuste asimétrico al equilibrio: evidencia para las principales ciudades de Colombia mediante modelos de corrección de error [Documento de Trabajo 26/01]**"
author:
  - Sergio A. Barona-Montoya^[Department of Economics and Finance, Pontificia Universidad Javeriana, Cali, Colombia. ORCID 0000-0001-8390-6673]
abstract: |
  [Abstract text to be added]
output:
  pdf_document:
    citation_package: natbib
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
    latex_engine: xelatex
bibliography: refs-ob-rif-informal.bib
geometry: margin=1in
fontsize: 12pt
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{natbib}
- \setcitestyle{authoryear,open={(},close={)}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
wd_path <- "C:\\Users\\danie\\OneDrive\\Escritorio\\Least-cost-diets-and-affordability\\Proyecto Interno\\"
knitr::opts_knit$set(root.dir = wd_path)
```

# Introducción

# Datos

## Fuentes de datos: precios minoristas (DANE–IPC)

La primera fuente de información corresponde a los precios minoristas reportados por el Departamento Administrativo Nacional de Estadística (DANE), utilizados como insumo para el cálculo del Índice de Precios al Consumidor (IPC) (DANE, 2024). El periodo de análisis se extiende desde enero de 1999 hasta marzo de 2018 y cubre las trece principales ciudades del país: Bogotá D.C., Medellín A.M., Cali A.M., Barranquilla A.M., Bucaramanga A.M., Manizales A.M., Pereira A.M., Cúcuta A.M., Pasto, Ibagué, Montería, Cartagena y Villavicencio.

Una característica central de esta base de datos es su estructura de clasificación, la cual se fundamenta en la canasta de seguimiento del IPC 2008. Dicha estructura organiza la información de precios a través de distintos niveles jerárquicos de agregación, lo que permite un análisis flexible y consistente de la dinámica de precios a diferentes escalas. En particular, la clasificación distingue entre cinco niveles: grupo, subgrupo, clase, gasto básico y artículo.

```{r, echo=FALSE, warning=FALSE}
date_tag <- "261225"

retail_99_18 = readxl::read_excel("Precios DANE\\OUTPUT_DANE\\precios_IPC_1999_2018.xlsx")

library(knitr)
kable(
  head(retail_99_18),
  caption = "First rows of the IPC retail price dataset (1999–2018)"
)
```

El nivel de **grupo** corresponde a la agregación más amplia de bienes y servicios, y agrupa conjuntos homogéneos de consumo. Cada grupo se subdivide en **subgrupos**, los cuales capturan categorías más específicas dentro de cada conjunto. A su vez, los subgrupos se desagregan en **clases**, que representan una segmentación aún más detallada del consumo. El nivel de **gasto básico** constituye la unidad operativa de seguimiento dentro del IPC y agrupa productos con características similares y patrones de consumo comparables. Finalmente, el nivel de **artículo** corresponde al producto específico cuyo precio es observado y reportado de manera directa.

Esta estructura jerárquica garantiza coherencia entre los distintos niveles de agregación y permite analizar la transmisión de precios desde desagregaciones finas hasta agregados más amplios, lo cual resulta particularmente relevante para la estimación de modelos de corrección de error y modelos de corrección de error asimétricos a nivel urbano.

## Fuentes de datos: precios mayoristas (SIPSA - DANE)

La información sobre los precios mayoristas corresponde a los datos del Sistema de Información de Precios y Abastecimiento del Sector Agropecuario (SIPSA), publicados por el DANE. El SIPSA no sólo informa, con frecuencia diaria, sobre los precios mayoristas de los productos agroalimentarios que se comercializan en el país; sino que, además, proporciona información, con frecuencia quincenal, sobre el nivel de abastecimiento de los alimentos en las ciudades. En este estudio se utilizarán datos de SIPSA para las tres principales ciudades de Colombia (Cali, Bogotá y Medellín) durante el período 2013:1 – 2024:1, con frecuencia mensual.

A continuación, se presenta la estructura de los datos:

```{r, echo=FALSE, warning=FALSE}
# Lista output
whole_list = vector(mode = "list", length = length(2013:2018))

# Cargar series de sipsa
for (k in 2013:2018) {
  whole_list[[k]] = readRDS(paste0("Precios al por mayor\\Bases historicas\\", k,".rds"))
}

# whole_18 significa whole hasta 2018
whole_18 <- do.call(rbind, whole_list)

library(knitr)

kable(
  head(whole_18),
  caption = "First rows of the SIPSA wholesale price dataset (2013–2018)"
)
```


# Metodología

## Mapeo IPC–SIPSA

La implementación de la metodología presupone un mapeo previo entre los alimentos reportados por el DANE en la construcción del IPC y los alimentos reportados por SIPSA (en adelante, **mapeo IPC–SIPSA**). En términos operativos, este procedimiento establece correspondencias entre ambas fuentes con el fin de asegurar comparabilidad conceptual y estadística en las series de precios. En particular, para cada alimento reportado en SIPSA se identifica un alimento equivalente dentro de la canasta del IPC. A continuación, se presenta el mapeo IPC–SIPSA.

```{r, echo=FALSE, warning=FALSE}
library(readxl)
ipc_sipsa = read_excel(paste0("working-papers\\working-paper-aecm\\input\\",
                             date_tag, "_mapeo_ipc_sipsa_ajustado.xlsx"))

library(knitr)

kable(
  head(ipc_sipsa),
  caption = "Mapeo IPC-SIPSA"
)
```

Es importante destacar que el mapeo no sigue una relación uno a uno, sino una relación **n a 1** (muchos a uno). En consecuencia, un mismo alimento definido en la base del IPC puede agrupar varios alimentos equivalentes reportados en SIPSA. (Por ejemplo, el ítem *arroz para seco* en el IPC puede corresponder, en SIPSA, a categorías como *arroz de primera*, *arroz de segunda* y *arroz excelso*). Este tipo de correspondencia refleja diferencias en el nivel de desagregación y en los criterios de clasificación entre las dos fuentes, y constituye un elemento central para la correcta construcción de series comparables en el análisis de transmisión de precios.

La siguiente tabla presenta el mapeo final utilizado en el análisis posterior:


```{r, echo=FALSE, warning=FALSE}
library(readxl)
coverage_city = read_excel(paste0("working-papers\\working-paper-aecm\\input\\",
                  date_tag, "_adj_coverage_ipc_sipsa.xlsx"))

library(knitr)

kable(
  coverage_city,
  caption = "Mapeo IPC-SIPSA: Alimentos incluidos en el análisis (Cali, Bogotá, Medellín)"
)
```

## Modelo de corrección de error

A partir de pruebas de Dickey–Fuller aumentadas (ADF), se examina la estacionariedad de las series temporales correspondientes a los precios de los alimentos analizados. La existencia de relaciones de cointegración entre los precios minoristas y mayoristas se evalúa mediante la prueba de Engle y Granger (1987).

Como señala Enders (2014), una característica fundamental de las variables cointegradas es que su trayectoria temporal está determinada por las desviaciones respecto del equilibrio de largo plazo. En consecuencia, las dinámicas de corto plazo deben estar condicionadas por dichas desviaciones. El modelo dinámico que permite capturar simultáneamente la relación de largo plazo y los ajustes de corto plazo es el modelo de corrección de error (*Error Correction Model*, ECM).

### Modelo de corrección de error estándar (ECM)

Sea $\ln(P_{it}^{min})$ el logaritmo natural del precio minorista y sea $\ln(P_{it}^{may})$ el logaritmo natural del precio mayorista del alimento $i$ en el período $t$. La relación de equilibrio de largo plazo entre ambos precios viene dada por:

$$
\ln(P_{it}^{min}) = \alpha_i + \beta_i \ln(P_{it}^{may}) + e_{it}.
$$

El término de corrección de error corresponde al residuo rezagado de la relación de cointegración:

$$
e_{i,t-1} = \ln(P_{i,t-1}^{min}) - \alpha_i - \beta_i \ln(P_{i,t-1}^{may}).
$$

Este término captura el desequilibrio existente en el período $t-1$. Si $e_{i,t-1} > 0$, el precio minorista se encuentra por encima del nivel consistente con el equilibrio de largo plazo, dado el precio mayorista. En este contexto, la dinámica de corto plazo se modela mediante la siguiente especificación ECM:

$$
\Delta \ln(P_{it}^{min}) =
c_{i0}
+ \sum_{p=1}^{P} \beta_{ip} \, \Delta \ln(P_{i,t-p}^{min})
+ \sum_{q=1}^{Q} \gamma_{iq} \, \Delta \ln(P_{i,t-q}^{may})
+ \theta_i \, e_{i,t-1}
+ u_{it}.
$$

En esta ecuación, los coeficientes $\beta_{ip}$ capturan la dinámica autorregresiva de corto plazo del precio minorista, mientras que los coeficientes $\gamma_{iq}$ reflejan el impacto de corto plazo de variaciones en el precio mayorista. El parámetro $\theta_i$ mide la velocidad de ajuste hacia el equilibrio de largo plazo. Se espera que $\theta_i < 0$, de modo que desviaciones positivas del equilibrio sean corregidas mediante reducciones en el crecimiento del precio minorista.

### Modelo de corrección de error asimétrico (A-ECM)

Siguiendo estudios previos sobre transmisión asimétrica de precios (por ejemplo, Chesnes, 2010), se implementa un modelo de corrección de error que permite capturar posibles asimetrías tanto en la velocidad como en el patrón de ajuste ante aumentos y reducciones en los precios. La especificación del modelo de corrección de error asimétrico (A-ECM) adopta la siguiente forma:

$$
\begin{aligned}
\Delta \ln(P_t^{min}) =\;&
\sum_{i=0}^{L_1^+} \beta_{1i}^+ \, \Delta^+ \ln(P_{t-i}^{may})
+ \sum_{i=0}^{L_1^-} \beta_{1i}^- \, \Delta^- \ln(P_{t-i}^{may}) \\
&+ \sum_{i=0}^{L_2^+} \beta_{2i}^+ \, \Delta^+ \ln(P_{t-i}^{min})
+ \sum_{i=0}^{L_2^-} \beta_{2i}^- \, \Delta^- \ln(P_{t-i}^{min}) \\
&+ \beta_3^+ \, e_{t-1}^+
+ \beta_3^- \, e_{t-1}^-
+ u_t .
\end{aligned}
$$

En esta expresión, $\Delta^+$ y $\Delta^-$ representan las variaciones positivas y negativas de las variables respectivas. El término de corrección de error $e_{t-1}$ captura la relación de equilibrio de largo plazo entre el precio minorista y el precio mayorista y se descompone en sus componentes positivo y negativo, $e_{t-1}^+$ y $e_{t-1}^-$.

Se espera que ambos coeficientes $\beta_3^+$ y $\beta_3^-$ sean negativos. En particular, si el precio minorista se encuentra por encima del equilibrio de largo plazo ($e_{t-1} > 0$), el ajuste debería materializarse a través de una reducción en el crecimiento del precio minorista; de manera análoga, si el precio minorista se sitúa por debajo del equilibrio ($e_{t-1} < 0$), el ajuste debería reflejarse en un aumento de dicho crecimiento.

Siguiendo la metodología en dos etapas propuesta por Engle y Granger (1987), la relación de largo plazo se estima a partir de la siguiente ecuación:

$$
\ln(P_{t-1}^{min}) = \alpha_0 + \beta_1 \ln(P_{t-1}^{may}) + e_{t-1}.
$$

Los residuales estimados de esta ecuación se incorporan posteriormente en la especificación A-ECM como términos de corrección de error, permitiendo evaluar empíricamente la presencia de ajustes asimétricos en la transmisión de precios.

# Resultados

## Análisis de series de tiempo

### Comportamiento de los precios minoristas y precios mayoristas

\begin{figure}[htbp]
\centering
\includegraphics{output/ts-output/log-levels-plots/261225_log_retail_vs_wholesale_7x3.png}
\caption{Log retail (IPC) and wholesale (SIPSA) prices by food and city}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{output/ts-output/seasonal-plots/261225_seasonal_retail_vs_wholesale_7x3_x13.png}
\caption{Log retail (IPC) and wholesale (SIPSA) prices by food and city}
\end{figure}

### Pruebas de raíz unitaria

```{r adf-table-q1, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(knitr)

# ---- 1) Choose which results to report (wholesale / retail) ----
# Assumes you already ran the script and have:
#   wholesale_results, retail_results
# If not, read from disk:

retail_results    <- readr::read_csv(file.path("working-papers\\working-paper-aecm\\output\\ts-output\\adf-test\\", paste0(date_tag, "_adf_retail_logSA_X13.csv")))

# ---- 2) Q1-style tidy table: stars + compact columns ----
make_adf_table <- function(res_df, title_caption) {

  res_df %>%
    filter(!is.na(test_stat)) %>%
    mutate(
      reject_10 = test_stat < cv_10pct,
      reject_05 = test_stat < cv_5pct,
      reject_01 = test_stat < cv_1pct,
      stars = case_when(
        reject_01 ~ "***",
        reject_05 ~ "**",
        reject_10 ~ "*",
        TRUE ~ ""
      ),
      test_stat_fmt = sprintf("%.3f%s", test_stat, stars),
      cv_1 = sprintf("%.3f", cv_1pct),
      cv_5 = sprintf("%.3f", cv_5pct),
      cv_10 = sprintf("%.3f", cv_10pct),
      adf_type = recode(adf_type, drift = "Intercept", trend = "Intercept + trend")
    ) %>%
    select(cod_mun, item, adf_type, test_stat_fmt, cv_1, cv_5, cv_10, n_obs) %>%
    arrange(cod_mun, item, adf_type) %>%
    rename(
      City = cod_mun,
      Item = item,
      Specification = adf_type,
      `ADF statistic` = test_stat_fmt,
      `CV 1%` = cv_1,
      `CV 5%` = cv_5,
      `CV 10%` = cv_10,
      N = n_obs
    ) %>%
    kable(
      booktabs = TRUE,
      caption = title_caption,
      align = "lllcclcl"
    )
}

# ---- 3) Print the two tables (Retail + Wholesale) ----

make_adf_table(
  retail_results,
  "Augmented Dickey Fuller tests on seasonally adjusted log retail prices (IPC). Notes: X 13 seasonal adjustment is applied to log price series; reported critical values correspond to the Dickey Fuller distribution. Significance: *** p<0.01, ** p<0.05, * p<0.10."
)
```


```{r adf-table2-q1, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(knitr)

# ---- 1) Choose which results to report (wholesale / retail) ----
# Assumes you already ran the script and have:
#   wholesale_results, retail_results
# If not, read from disk:

wholesale_results    <- readr::read_csv(file.path("working-papers\\working-paper-aecm\\output\\ts-output\\adf-test\\", paste0(date_tag, "_adf_wholesale_logSA_X13.csv")))

# ---- 2) Q1-style tidy table: stars + compact columns ----
make_adf_table <- function(res_df, title_caption) {

  res_df %>%
    filter(!is.na(test_stat)) %>%
    mutate(
      reject_10 = test_stat < cv_10pct,
      reject_05 = test_stat < cv_5pct,
      reject_01 = test_stat < cv_1pct,
      stars = case_when(
        reject_01 ~ "***",
        reject_05 ~ "**",
        reject_10 ~ "*",
        TRUE ~ ""
      ),
      test_stat_fmt = sprintf("%.3f%s", test_stat, stars),
      cv_1 = sprintf("%.3f", cv_1pct),
      cv_5 = sprintf("%.3f", cv_5pct),
      cv_10 = sprintf("%.3f", cv_10pct),
      adf_type = recode(adf_type, drift = "Intercept", trend = "Intercept + trend")
    ) %>%
    select(cod_mun, item, adf_type, test_stat_fmt, cv_1, cv_5, cv_10, n_obs) %>%
    arrange(cod_mun, item, adf_type) %>%
    rename(
      City = cod_mun,
      Item = item,
      Specification = adf_type,
      `ADF statistic` = test_stat_fmt,
      `CV 1%` = cv_1,
      `CV 5%` = cv_5,
      `CV 10%` = cv_10,
      N = n_obs
    ) %>%
    kable(
      booktabs = TRUE,
      caption = title_caption,
      align = "lllcclcl"
    )
}

# ---- 3) Print the two tables (Retail + Wholesale) ----
make_adf_table(
  wholesale_results,
  "Augmented Dickey Fuller tests on seasonally adjusted log wholesale prices (SIPSA). Notes: X 13 seasonal adjustment is applied to log price series; reported critical values correspond to the Dickey Fuller distribution. Significance: *** p<0.01, ** p<0.05, * p<0.10."
)

```

## Análisis de cointegración de Engle-Granger

Las Tablas X e Y reportan los resultados de los test de cointegración de Engle-Granger entre los precios minoristas (IPC) y mayoristas (SIPSA), expresados en logaritmos. Puesto que el estadístico dependen de la especificación, la longitud del rezago en la regresión "auxiliar" se selecciona de acuerdo con criterios de información (AIC y BIC). La Tabla X presenta los resultados cuando la selección del rezago óptimo se realiza a partir de una regresión ADF con constante (especificación "drift"). En contraste, la Tabla Y reporta los resultados correspondientes a una regresión ADF que incluye tanto la constante como la tendencia lineal. Finalmente, la inferencia final sobre la cointegración es implementada usando la función ´coint.test´, que considera los valores críticos y p-valores de MacKinnon.



```{r coint-eg-q1-tables, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(knitr)
library(kableExtra)
library(readr)

# ------------------------------------------------------------------
# Load results (or assume they already exist in memory)
# ------------------------------------------------------------------
out_dir = "working-papers/working-paper-aecm/output/ts-output/coint-test"
# If already in memory, comment these lines out
coint_drift <- read_csv(
  file.path(out_dir, paste0(date_tag,
    "_coint_results_SA_logprices_IC_BIC_maxlag12_drift.csv"))
)

coint_trend <- read_csv(
  file.path(out_dir, paste0(date_tag,
    "_coint_results_SA_logprices_IC_BIC_maxlag12_trend.csv"))
)

# ------------------------------------------------------------------
# Helper: format EG results for publication
# ------------------------------------------------------------------
format_coint_table <- function(df) {
  df %>%
    filter(!is.na(EG),
           type %in% c("type 1", "type 2")) %>%
    mutate(
      stars = case_when(
        p.value < 0.01 ~ "***",
        p.value < 0.05 ~ "**",
        p.value < 0.10 ~ "*",
        TRUE ~ ""
      ),
      EG_fmt = sprintf("%.3f%s", EG, stars),
      p_fmt  = sprintf("%.3f", p.value)
    ) %>%
    select(
      City = city,
      `Retail item (IPC)` = articulo_ipc,
      `Wholesale item (SIPSA)` = alimento_sipsa,
      Specification = type,
      `EG statistic` = EG_fmt,
      `p-value` = p_fmt
    ) %>%
    arrange(City, `Retail item (IPC)`, Specification)
}

tbl_drift <- format_coint_table(coint_drift)
tbl_trend <- format_coint_table(coint_trend)

# ------------------------------------------------------------------
# Table A: Lag selection using ADF with intercept (drift)
# ------------------------------------------------------------------
kable(
  tbl_drift,
  booktabs = TRUE,
  caption = paste0(
    "Engle–Granger cointegration tests using seasonally adjusted log prices. ",
    "Lag length selected by BIC from residual ADF regression with intercept."
  ),
  align = "lllclccc"
) %>%
  kable_styling(
    latex_options = c("hold_position", "scale_down"),
    font_size = 9
  )

cat("\n\n")

# ------------------------------------------------------------------
# Table B: Lag selection using ADF with intercept and trend
# ------------------------------------------------------------------
kable(
  tbl_trend,
  booktabs = TRUE,
  caption = paste0(
    "Engle–Granger cointegration tests using seasonally adjusted log prices. ",
    "Lag length selected by BIC from residual ADF regression with intercept and trend."
  ),
  align = "lllclccc"
) %>%
  kable_styling(
    latex_options = c("hold_position", "scale_down"),
    font_size = 9
  )
```

Adicionalmente, se consideran dos especificaciones estándar del test de Engle-Granger. La especificación "type 1" corresponde a un modelo sin tendencia; y la especificación "type 2", a un modelo con tendencia lineal. En conjunción con los resultados de las pruebas de raíz unitaria, los resultados de ambas tablas proporcionan evidencia en favor de la presencia de cointegración para los siguientes casos: en Cali, el arroz; en Medellín, el arroz, la papa y la yuca.


### Modelo de Corrección de Error simétrico (ECM)

A partir de las pruebas de raíz unitaria y el test de cointegración, el análisis subsiguiente considera únicamente los siguientes cuatro alimentos: (1) arroz, (2) papa, (3) plátano y (4) yuca. La siguiente tabla presenta los resultados del modelo de corrección de error simétrico (ECM). La longitud del rezago fue seleccionada a partir de criterios de información (AIC y BIC).

```{r ecm-tables-setup, echo=FALSE, message=FALSE, warning=FALSE}
library(readxl)
library(dplyr)
library(knitr)
library(kableExtra)

date_tag <- "261225"
out_dir_ecm <- "working-papers\\working-paper-aecm\\output\\ts-ecm\\"

kable_q1 <- function(df, caption, label){
  kable(df, format = "latex", booktabs = TRUE, caption = caption, label = label, align = "l") %>%
    kable_styling(
      latex_options = c("hold_position", "striped", "scale_down"),
      font_size = 9
    )
}
```


```{r tab-ecm-2-longrun, echo=FALSE, message=FALSE, warning=FALSE}
tab2 <- read_excel(file.path(out_dir_ecm, paste0(date_tag, "_table2_longrun.xlsx")))

kable_q1(
  tab2,
  caption = "Long-run relationship between log retail prices (IPC) and log wholesale prices (SIPSA) by city and pair. The table reports the slope estimate (b), standard error, and p-value from the long-run regression.",
  label = "tab:longrun"
)
```



```{r tab-ecm-3-cali, echo=FALSE, message=FALSE, warning=FALSE}
tab3 <- read_excel(file.path(out_dir_ecm, paste0(date_tag, "_table3_ecm_cali.xlsx")))

kable_q1(
  tab3,
  caption = "Error correction model (ECM) estimates for Cali. The ECM is estimated under the Enders restriction (same lag length for \\(\\Delta y\\) and \\(\\Delta x\\), no contemporaneous \\(\\Delta x_t\\)).",
  label = "tab:ecm_cali"
)
```




```{r tab-ecm-4-bogota, echo=FALSE, message=FALSE, warning=FALSE}
tab4 <- read_excel(file.path(out_dir_ecm, paste0(date_tag, "_table4_ecm_bogota.xlsx")))

kable_q1(
  tab4,
  caption = "Error correction model (ECM) estimates for Bogotá. The ECM is estimated under the Enders restriction (same lag length for \\(\\Delta y\\) and \\(\\Delta x\\), no contemporaneous \\(\\Delta x_t\\)).",
  label = "tab:ecm_bogota"
)
```


```{r tab-ecm-5-medellin, echo=FALSE, message=FALSE, warning=FALSE}
tab5 <- read_excel(file.path(out_dir_ecm, paste0(date_tag, "_table5_ecm_medellin.xlsx")))

kable_q1(
  tab5,
  caption = "Error correction model (ECM) estimates for Medellín. The ECM is estimated under the Enders restriction (same lag length for \\(\\Delta y\\) and \\(\\Delta x\\), no contemporaneous \\(\\Delta x_t\\)).",
  label = "tab:ecm_medellin"
)
```


## Análisis de cointegración asimétrica


### Modelo TAR (Threshold Autoregressive)

Sea \(P^{may}_t\) el **precio mayorista** (SIPSA) y \(P^{min}_t\) el **precio minorista** (IPC–DANE) en el período \(t\). Trabajamos en logaritmos:

\[
p^{may}_t = \ln\!\left(P^{may}_t\right), 
\qquad 
p^{min}_t = \ln\!\left(P^{min}_t\right).
\]

En la primera etapa del procedimiento de Engle--Granger se estima la relación de equilibrio de largo plazo entre precios mayoristas y minoristas:

\[
p^{may}_t = \alpha_0 + \alpha_1 p^{min}_t + \mu_t,
\]

donde \(\mu_t\) es el residuo que captura el **desequilibrio** respecto al equilibrio de largo plazo. Si existe cointegración, \(\mu_t\) es un proceso estacionario.

El modelo TAR (Threshold Autoregressive) permite que la velocidad de ajuste hacia el equilibrio dependa del **signo del desequilibrio**. La dinámica del residuo se especifica como:

\[
\Delta \mu_t 
= I_t \rho_1 \mu_{t-1}
+ (1 - I_t)\rho_2 \mu_{t-1}
+ \varepsilon_t,
\]

donde \(\varepsilon_t\) es un término de error con media cero y varianza constante, y la función indicadora tipo Heaviside se define como:

\[
I_t =
\begin{cases}
1 & \text{si } \mu_{t-1} \ge \tau, \\
0 & \text{si } \mu_{t-1} < \tau.
\end{cases}
\]

Siguiendo a Enders y Siklos, en la mayoría de aplicaciones empíricas se fija \(\tau = 0\), de modo que el umbral coincide con el equilibrio de largo plazo.

El sistema converge al equilibrio si \(\rho_1 < 0\), \(\rho_2 < 0\) y \((1+\rho_1)(1+\rho_2) < 1\). El ajuste es **simétrico** únicamente cuando \(\rho_1 = \rho_2\), caso en el cual el modelo TAR se reduce al modelo lineal estándar de corrección de errores del enfoque Engle--Granger.


### Modelo M-TAR (Momentum Threshold Autoregressive)

Una extensión del modelo TAR es el modelo M-TAR, en el cual el régimen de ajuste depende de la **dirección del cambio** del desequilibrio en el período anterior, y no de su nivel.

El modelo M-TAR se especifica como:

\[
\Delta \mu_t 
= M_t \rho_1 \mu_{t-1}
+ (1 - M_t)\rho_2 \mu_{t-1}
+ \varepsilon_t,
\]

donde la función indicadora \(M_t\) se define como:

\[
M_t =
\begin{cases}
1 & \text{si } \Delta \mu_{t-1} \ge \tau, \\
0 & \text{si } \Delta \mu_{t-1} < \tau.
\end{cases}
\]

En aplicaciones empíricas suele fijarse \(\tau = 0\), aunque el umbral también puede estimarse de manera consistente siguiendo el procedimiento propuesto por Chan (1993).

El modelo M-TAR permite capturar ajustes asimétricos asociados al **momentum del desequilibrio**, es decir, respuestas distintas cuando la brecha entre precios mayoristas y minoristas se está ampliando (\(\Delta \mu_{t-1} \ge 0\)) frente a cuando se está cerrando (\(\Delta \mu_{t-1} < 0\)). La cointegración con ajuste M-TAR se verifica cuando \(\rho_1 < 0\) y \(\rho_2 < 0\), indicando convergencia al equilibrio de largo plazo con dinámica no lineal.


```{r table7, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
library(stringr)
library(knitr)
library(kableExtra)

# 1) Load IPC-dependent results
tables_path <- file.path(
  "working-papers/working-paper-aecm/output-paper/tables/tables_12_ipc_dep.rds"
)

if (!file.exists(tables_path)) {
  stop(paste0(
    "File not found: ", tables_path, "\n",
    "First run the IPC-dependent pipeline."
  ))
}

tables_12 <- readRDS(tables_path)

# 2) IPC foods to keep
alimentos_keep <- c(
  "ARROZ PARA SECO",
  "CEBOLLA CABEZONA",
  "PAPA",
  "PLÁTANO"
)

# 3) City dictionary
city_lookup <- c(
  "05001" = "MEDELLÍN",
  "11001" = "BOGOTÁ",
  "76001" = "CALI"
)

nms <- names(tables_12)
if (is.null(nms)) stop("'tables_12' has no names().")

# 4) Loop
for (nm in nms) {

  # Extract cod_mun
  cod_mun_match <- str_match(nm, "cod_mun=([0-9]+)")
  cod_mun <- cod_mun_match[,2]

  # Extract articulo_ipc
  articulo_match <- str_match(nm, "articulo_ipc=(.*)$")
  articulo_ipc <- articulo_match[,2]

  # Keep only desired foods
  if (!is.na(articulo_ipc) && articulo_ipc %in% alimentos_keep) {

    ciudad <- city_lookup[cod_mun]

    cat("\n\n### Table 7 – ", ciudad, " – ", articulo_ipc, sep = "")

    print(
      kable(tables_12[[nm]]$table7,
            booktabs = TRUE,
            digits = 3) %>%
        kable_styling(full_width = FALSE,
                      position = "center")
    )
  }
}

```

### Modelo de Corrección de Error Asimétrico (A-ECM)

Sea \(P^{may}_t\) el **precio mayorista** (SIPSA) y \(P^{min}_t\) el **precio minorista** (IPC–DANE) en el período \(t\). Trabajamos en logaritmos:

\begin{equation}
p^{may}_t=\ln(P^{may}_t), 
\qquad 
p^{min}_t=\ln(P^{min}_t).
\end{equation}

En la primera etapa (Engle--Granger) se estima la relación de equilibrio de largo plazo:

\begin{equation}
p^{may}_t = \alpha_0 + \alpha_1 p^{min}_t + \mu_t,
\end{equation}

donde \(\mu_t\) es el residuo (desequilibrio) respecto al equilibrio.

Para construir el A-ECM asimétrico, se usa el umbral M-TAR \(\tau_x\) (estimado previamente) con base en el *momentum* del desequilibrio:

\begin{equation}
M_t=
\begin{cases}
1 & \text{si } \Delta \mu_{t-1}\ge \tau_x,\\
0 & \text{si } \Delta \mu_{t-1}< \tau_x.
\end{cases}
\end{equation}

y se definen los términos de corrección de error asimétricos:

\begin{equation}
\mu^{-}_{t-1}=M_t\mu_{t-1},
\qquad
\mu^{+}_{t-1}=(1-M_t)\mu_{t-1}.
\end{equation}

El sistema A-ECM (con intercepto) para \(\Delta p^{may}_t\) y \(\Delta p^{min}_t\) se especifica como:

\begin{equation}
\Delta p^{may}_t = c_1 
+ \sum_{j=1}^{k} a_{11,j}\Delta p^{may}_{t-j}
+ \sum_{j=1}^{k} a_{12,j}\Delta p^{min}_{t-j}
+ \lambda^-_1 \mu^{-}_{t-1}
+ \lambda^+_1 \mu^{+}_{t-1}
+ u_{1t},
\end{equation}

\begin{equation}
\Delta p^{min}_t = c_2 
+ \sum_{j=1}^{k} a_{21,j}\Delta p^{may}_{t-j}
+ \sum_{j=1}^{k} a_{22,j}\Delta p^{min}_{t-j}
+ \lambda^-_2 \mu^{-}_{t-1}
+ \lambda^+_2 \mu^{+}_{t-1}
+ u_{2t}.
\end{equation}

Los coeficientes \(\lambda^-_1,\lambda^+_1,\lambda^-_2,\lambda^+_2\) capturan velocidades de ajuste diferentes según el régimen (cuando el desequilibrio venía aumentando o disminuyendo). Adicionalmente, se reportan pruebas \(F\) sobre la dinámica de corto plazo: restricciones tipo \(A_{ij}(L)=0\) (rezagos conjuntos) en cada ecuación.

```{r aecm_table, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
library(stringr)
library(dplyr)
library(purrr)
library(knitr)
library(kableExtra)

# Cargar resultados
aecm_path <- file.path("working-papers/working-paper-aecm/output-paper/tables/aecm_retail_results_12.rds")
if (!file.exists(aecm_path)) stop("No encuentro: ", aecm_path)
aecm_list <- readRDS(aecm_path)
if (is.null(names(aecm_list))) names(aecm_list) <- paste0("group_", seq_along(aecm_list))

# Selección de alimentos (IPC)
foods_keep <- c("ARROZ PARA SECO", "CEBOLLA CABEZONA", "PAPA", "PLÁTANO")

# Diccionario ciudades
city_lookup <- c(
  "05001" = "MEDELLÍN",
  "11001" = "BOGOTÁ",
  "76001" = "CALI"
)

# Helpers
extract_cod_mun <- function(x) {
  m <- str_match(x, "cod_mun=([0-9]+)")
  ifelse(is.na(m[,2]), NA_character_, m[,2])
}

pretty_key <- function(x) {
  x %>%
    str_replace_all("__", " | ") %>%
    str_replace_all("cod_mun=", "cod_mun: ") %>%
    str_replace_all("articulo_ipc=", "articulo_ipc: ")
}

fmt_et <- function(b, t) {
  if (is.na(b) || is.na(t)) return(NA_character_)
  sprintf("%.3f (%.2f)", b, t)
}

# ECUACIÓN 
make_equation_align <- function(mod, p_lags) {
  cc <- summary(mod)$coefficients
  rn <- rownames(cc)

  get <- function(term) {
    if (!(term %in% rn)) return(NULL)
    c(b = as.numeric(cc[term, "Estimate"]),
      t = as.numeric(cc[term, "t value"]))
  }

  ic <- get("(Intercept)")
  if (is.null(ic)) stop("El modelo no tiene intercepto.")

  pieces <- list()
  pieces[[1]] <- paste0(
    "\\Delta p^{min}_{t} &= ",
    sprintf("%.3f", ic["b"]), "\\;(", sprintf("%.2f", ic["t"]), ")"
  )

  add_term_piece <- function(b, t, latex_term) {
    sgn <- ifelse(b >= 0, "+", "−")
    paste0("&\\quad ", sgn, " ",
           sprintf("%.3f", abs(b)), "\\,",
           latex_term, "\\;(", sprintf("%.2f", t), ")")
  }

  if (p_lags > 0) {
    for (j in seq_len(p_lags)) {
      tr <- get(paste0("dpR_l", j))
      if (!is.null(tr)) {
        pieces[[length(pieces) + 1]] <- add_term_piece(
          tr["b"], tr["t"], paste0("\\Delta p^{min}_{t-", j, "}")
        )
      }
    }

    for (j in seq_len(p_lags)) {
      tw <- get(paste0("dpW_l", j))
      if (!is.null(tw)) {
        pieces[[length(pieces) + 1]] <- add_term_piece(
          tw["b"], tw["t"], paste0("\\Delta p^{may}_{t-", j, "}")
        )
      }
    }
  }

  tp <- get("mu_plus_l1")
  if (!is.null(tp)) pieces[[length(pieces) + 1]] <- add_term_piece(tp["b"], tp["t"], "\\mu^{+}_{t-1}")

  tm <- get("mu_minus_l1")
  if (!is.null(tm)) pieces[[length(pieces) + 1]] <- add_term_piece(tm["b"], tm["t"], "\\mu^{-}_{t-1}")

  pieces[[length(pieces) + 1]] <- "&\\quad +\\, \\varepsilon_t"

  eq <- paste(pieces, collapse = " \\\\\n")
  paste0("\\[\n\\begin{aligned}\n", eq, "\n\\end{aligned}\n\\]\n")
}

# tabla compacta
make_compact_table <- function(obj, mod, p_lags) {
  cc <- summary(mod)$coefficients
  rn <- rownames(cc)

  safe <- function(term, col) {
    if (!(term %in% rn)) return(NA_real_)
    as.numeric(cc[term, col])
  }

  meta <- tibble(
    item = c("p_ECM", "τ_x", "ρ1 (M-TAR)", "ρ2 (M-TAR)", "p_M-TAR"),
    value = c(
      as.character(p_lags),
      ifelse(!is.null(obj$tau_x), sprintf("%.5f", obj$tau_x), NA_character_),
      ifelse(!is.null(obj$rho1_mtar), sprintf("%.4f", obj$rho1_mtar), NA_character_),
      ifelse(!is.null(obj$rho2_mtar), sprintf("%.4f", obj$rho2_mtar), NA_character_),
      ifelse(!is.null(obj$p_mtar), as.character(obj$p_mtar), NA_character_)
    )
  )

  lag_terms_R <- if (p_lags > 0) paste0("dpR_l", seq_len(p_lags)) else character(0)
  lag_terms_W <- if (p_lags > 0) paste0("dpW_l", seq_len(p_lags)) else character(0)

  lag_rows <- bind_rows(
    tibble(term = lag_terms_R,
           item = if (p_lags > 0) paste0("a", seq_len(p_lags), ": Δp^{min}_{t-", seq_len(p_lags), "}") else character(0)),
    tibble(term = lag_terms_W,
           item = if (p_lags > 0) paste0("b", seq_len(p_lags), ": Δp^{may}_{t-", seq_len(p_lags), "}") else character(0)),
    tibble(term = c("mu_plus_l1","mu_minus_l1"),
           item = c("φ+: μ^{+}_{t-1}","φ−: μ^{-}_{t-1}"))
  ) %>%
    mutate(
      est = map_dbl(term, ~safe(.x, "Estimate")),
      tt  = map_dbl(term, ~safe(.x, "t value")),
      value = mapply(fmt_et, est, tt)
    ) %>%
    select(item, value)

  bind_rows(meta, tibble(item="—", value="—"), lag_rows)
}

# Loop
for (nm in names(aecm_list)) {

  obj <- aecm_list[[nm]]

  food_here <- if (!is.null(obj$articulo_ipc)) as.character(obj$articulo_ipc) else NA_character_
  if (is.na(food_here) || !(food_here %in% foods_keep)) next

  # ciudad
  cod_mun <- NA_character_
  if (!is.null(obj$cod_mun)) cod_mun <- as.character(obj$cod_mun)
  if (is.na(cod_mun) && !is.null(obj$name_key)) cod_mun <- extract_cod_mun(as.character(obj$name_key))
  if (is.na(cod_mun)) cod_mun <- extract_cod_mun(as.character(nm))

  ciudad <- unname(city_lookup[cod_mun])
  if (is.na(ciudad) || is.null(ciudad)) ciudad <- paste0("cod_mun ", cod_mun)

  ttl_raw <- if (!is.null(obj$name_key)) as.character(obj$name_key) else as.character(nm)
  ttl <- pretty_key(ttl_raw)

  cat("\n\n## A-ECM (minorista en función de mayorista) – ", ciudad, " – ", food_here, "\n\n", sep = "")
  cat("\n\n### ", ttl, "\n\n", sep = "")

  p_ecm <- if (!is.null(obj$p_ecm)) as.integer(obj$p_ecm) else 1L
  cat("**p_ECM (rezagos corto plazo)** = ", p_ecm, "  \n", sep = "")
  if (!is.null(obj$tau_x)) cat("**$\\tau_x$ (umbral M-TAR)** = ", sprintf("%.5f", obj$tau_x), "  \n\n", sep = "")

  cat(make_equation_align(obj$mod_retail, p_lags = p_ecm), "\n\n")

  tab <- make_compact_table(obj, obj$mod_retail, p_lags = p_ecm)
  print(
    kable(tab, booktabs = TRUE, align = c("l","l")) %>%
      kable_styling(full_width = FALSE, position = "center")
  )

  if (!is.null(obj$lb_h) && !is.null(obj$lb_p)) {
    cat("\n\n*Ljung–Box*: p(Q(", obj$lb_h, ")) = ", sprintf("%.3f", obj$lb_p), "\n\n", sep = "")
  }
}

```





